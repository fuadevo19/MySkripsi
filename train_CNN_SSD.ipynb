{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23778de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path dataset\n",
    "IMG_DIR = '/kaggle/input/tajwid-dataset/images'\n",
    "ANN_DIR = '/kaggle/input/tajwid-dataset/annotations'\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['background', 'ikhfa', 'idgham', 'idzhar', 'iklab']  # 0 is background\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TajwidDataset(Dataset):\n",
    "    def __init__(self, img_dir, ann_dir, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.transforms = transforms\n",
    "        self.images = list(sorted(os.listdir(img_dir)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        img_filename = os.path.splitext(self.images[idx])[0]\n",
    "        ann_path = os.path.join(self.ann_dir, img_filename + '.xml')\n",
    "\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text\n",
    "            bbox = obj.find('bndbox')\n",
    "            boxes.append([\n",
    "                int(bbox.find('xmin').text),\n",
    "                int(bbox.find('ymin').text),\n",
    "                int(bbox.find('xmax').text),\n",
    "                int(bbox.find('ymax').text)\n",
    "            ])\n",
    "            labels.append(CLASS_NAMES.index(label))\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=img, bboxes=boxes, class_labels=labels)\n",
    "            img = sample['image']\n",
    "            img = img.float() / 255.0\n",
    "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "            target['labels'] = torch.tensor(sample['class_labels'], dtype=torch.int64)\n",
    "        else:\n",
    "            img = F.to_tensor(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        # üîÑ Ukuran teks sangat kecil/besar dan zoom\n",
    "        A.OneOf([\n",
    "            A.RandomScale(scale_limit=(-0.6, 0.4), p=0.6),  # Teks kecil/besar\n",
    "            A.RandomSizedBBoxSafeCrop(height=224, width=224, erosion_rate=0.2, p=0.3),  # Zoom-in ke objek\n",
    "        ], p=1.0),\n",
    "\n",
    "        # üîÑ Flip horizontal sebagai variasi tampilan\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        # üí° Pencahayaan dan kontras\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.RandomGamma(p=0.3),\n",
    "        A.OneOf([\n",
    "            A.Blur(blur_limit=5, p=0.3),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.3),\n",
    "            A.MotionBlur(blur_limit=5, p=0.3),\n",
    "        ], p=0.4),\n",
    "\n",
    "        # üß© Tambahan untuk tekstur buruk atau noise\n",
    "        A.OneOf([\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.3), p=0.3),  # Simulasi noise ISO\n",
    "            A.ImageCompression(quality_lower=30, quality_upper=60, p=0.3),     # Simulasi gambar pecah\n",
    "        ], p=0.5),\n",
    "\n",
    "        # üìê Rotasi & geser\n",
    "        A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.2, rotate_limit=15, p=0.6),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2()\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "\n",
    "\n",
    "def get_val_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(224,224),\n",
    "        ToTensorV2()\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeecb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TajwidDataset(IMG_DIR, ANN_DIR, transforms=get_train_transform())\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "val_dataset.dataset.transforms = get_val_transform()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=3, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ssdlite320_mobilenet_v3_large(pretrained=True)\n",
    "model.head.classification_head.num_classes = NUM_CLASSES\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(pbar):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += losses.item()\n",
    "        pbar.set_postfix({\n",
    "        'Batch': f\"{batch_idx+1}/{len(data_loader)}\",\n",
    "        'Loss': losses.item()\n",
    "    })\n",
    "\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for output, target in zip(outputs, targets):\n",
    "                pred_labels = output['labels']\n",
    "                true_labels = target['labels']\n",
    "                total += true_labels.size(0)\n",
    "                correct += (pred_labels == true_labels).sum().item()\n",
    "    return correct / total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d29136",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 100\n",
    "best_acc = 0.0\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch+1)\n",
    "    val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model, 'TajwidModelCNNSSD_FULL.pth') \n",
    "\n",
    "print(\"‚úÖ Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a27cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.ops as ops\n",
    "\n",
    "def plot_prediction(model, image_path, threshold=0.5, iou_thresh=0.3):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and resize image\n",
    "    original_img = Image.open(image_path).convert(\"RGB\")\n",
    "    orig_w, orig_h = original_img.size\n",
    "    img_resized = original_img.resize((224, 224))\n",
    "    img_tensor = F.to_tensor(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)[0]\n",
    "\n",
    "    # Simpan semua hasil awal\n",
    "    all_boxes = outputs['boxes']\n",
    "    all_labels = outputs['labels']\n",
    "    all_scores = outputs['scores']\n",
    "      # Simpan hasil yang disaring\n",
    "\n",
    "    final_boxes = []\n",
    "    final_labels = []\n",
    "    final_scores = []\n",
    "\n",
    "    # Loop tiap kelas (selain background) untuk NMS per kelas\n",
    "    for class_idx in range(1, len(CLASS_NAMES)):\n",
    "        cls_mask = all_labels == class_idx\n",
    "        cls_boxes = all_boxes[cls_mask]\n",
    "        cls_scores = all_scores[cls_mask]\n",
    "\n",
    "        if cls_boxes.size(0) == 0:\n",
    "            continue\n",
    "        \n",
    "        keep = ops.nms(cls_boxes, cls_scores, iou_thresh)\n",
    "        for idx in keep:\n",
    "            if cls_scores[idx] >= threshold:\n",
    "                final_boxes.append(cls_boxes[idx])\n",
    "                final_labels.append(class_idx)\n",
    "                final_scores.append(cls_scores[idx])\n",
    "\n",
    "    # Gambar hasil pada original image\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.imshow(original_img)\n",
    "\n",
    "    scale_x = orig_w / 224\n",
    "    scale_y = orig_h / 224\n",
    "    if len(final_boxes) == 0:\n",
    "        print(\"‚ö†Ô∏è Tidak ada prediksi valid yang ditemukan.\")\n",
    "    else:\n",
    "        for box, label, score in zip(final_boxes, final_labels, final_scores):\n",
    "            x1, y1, x2, y2 = box.cpu().numpy()\n",
    "            x1 *= scale_x\n",
    "            x2 *= scale_x\n",
    "            y1 *= scale_y\n",
    "            y2 *= scale_y\n",
    "\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                                    fill=False, edgecolor='red', linewidth=2))\n",
    "            ax.text(x1, y1, f\"{CLASS_NAMES[label]} ({score*100:.1f}%)\",\n",
    "                    fontsize=12, color='red')\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd77a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Plot Train Loss dan Validation Accuracy ===\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, marker='o', label='Train Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, val_accuracies, marker='s', color='green', label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a790d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate IoU (Intersection over Union) between two boxes.\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15531862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_detection(model, data_loader, device, iou_threshold=0.5, score_threshold=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    true_positives = defaultdict(int)\n",
    "    false_positives = defaultdict(int)\n",
    "    false_negatives = defaultdict(int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            outputs = model(images)\n",
    "            for output, target in zip(outputs, targets):\n",
    "                pred_boxes = output['boxes']\n",
    "                pred_labels = output['labels']\n",
    "                pred_scores = output['scores']\n",
    "\n",
    "                gt_boxes = target['boxes']\n",
    "                gt_labels = target['labels']\n",
    "\n",
    "                matched_gt = []\n",
    "\n",
    "                for pred_box, pred_label, pred_score in zip(pred_boxes, pred_labels, pred_scores):\n",
    "                    if pred_score < score_threshold:\n",
    "                        continue\n",
    "                    best_iou = 0\n",
    "                    best_gt_idx = -1\n",
    "                    for gt_idx, (gt_box, gt_label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "                        if gt_idx in matched_gt:\n",
    "                            continue\n",
    "                        if pred_label != gt_label:\n",
    "                            continue\n",
    "\n",
    "                        iou = calculate_iou(pred_box.cpu().numpy(), gt_box.cpu().numpy())\n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "                            best_gt_idx = gt_idx\n",
    "\n",
    "                    if best_iou >= iou_threshold and best_gt_idx != -1:\n",
    "                        true_positives[int(pred_label)] += 1\n",
    "                        matched_gt.append(best_gt_idx)\n",
    "                    else:\n",
    "                        false_positives[int(pred_label)] += 1\n",
    "\n",
    "                # Hitung false negatives (ground truth yang tidak ketemu)\n",
    "                for gt_idx, gt_label in enumerate(gt_labels):\n",
    "                    if gt_idx not in matched_gt:\n",
    "                        false_negatives[int(gt_label)] += 1\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1_score = {}\n",
    "\n",
    "    for label in range(len(CLASS_NAMES)):\n",
    "        tp = true_positives[label]\n",
    "        fp = false_positives[label]\n",
    "        fn = false_negatives[label]\n",
    "\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "        precision[label] = prec\n",
    "        recall[label] = rec\n",
    "        f1_score[label] = f1\n",
    "\n",
    "        valid_labels = [i for i in range(1, len(CLASS_NAMES))]  # Skip background (label 0)\n",
    "\n",
    "        macro_precision = np.mean([precision.get(i, 0.0) for i in valid_labels])\n",
    "        macro_recall = np.mean([recall.get(i, 0.0) for i in valid_labels])\n",
    "        macro_f1 = np.mean([f1_score.get(i, 0.0) for i in valid_labels])\n",
    "\n",
    "\n",
    "    return precision, recall, f1_score, macro_precision, macro_recall, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7283aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, macro_precision, macro_recall, macro_f1 = evaluate_detection(model, val_loader, device)\n",
    "\n",
    "print(\"\\nüìä Evaluation Results (Validation Set)\")\n",
    "print(\"=\"*60)\n",
    "for label_idx in range(1, len(CLASS_NAMES)):  # Lewati background\n",
    "    print(f\"Class: {CLASS_NAMES[label_idx]}\")\n",
    "    print(f\" - Precision: {precision[label_idx]:.4f}\")\n",
    "    print(f\" - Recall   : {recall[label_idx]:.4f}\")\n",
    "    print(f\" - F1-Score : {f1_score[label_idx]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nüìà Macro Averages:\")\n",
    "print(f\"Overall Precision: {macro_precision:.4f}\")\n",
    "print(f\"Overall Recall   : {macro_recall:.4f}\")\n",
    "print(f\"Overall F1-Score : {macro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(model, '/kaggle/input/data-test/data_test/other2.png') #path untuk memanggil image sesuaikan juga path di atas yang digunakan untuk kagle \n",
    "                                                                        #di ganti ke local happy coding!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
